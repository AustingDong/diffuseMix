Epoch, lr, Train_Loss, Train_Acc, Test_Acc
===== Using Torch AMP =====
0, 0.0250, 5.3580, 0.640%, 0.945%
1, 0.0250, 5.2111, 1.074%, 1.231%
2, 0.0250, 5.1573, 1.386%, 1.604%
3, 0.0250, 5.1167, 1.710%, 1.405%
4, 0.0249, 5.0474, 2.260%, 2.214%
5, 0.0249, 4.9555, 3.285%, 3.296%
6, 0.0249, 4.8117, 4.257%, 4.825%
7, 0.0248, 4.5469, 6.980%, 5.696%
8, 0.0248, 4.2079, 11.208%, 6.529%
9, 0.0247, 3.7668, 19.386%, 11.342%
10, 0.0246, 3.2320, 32.165%, 23.915%
11, 0.0245, 2.7346, 46.243%, 32.110%
12, 0.0245, 2.3249, 59.441%, 43.676%
13, 0.0244, 1.9937, 70.661%, 42.768%
14, 0.0243, 1.7321, 79.753%, 38.975%
15, 0.0242, 1.5511, 86.208%, 60.950%
16, 0.0240, 1.4051, 91.088%, 63.089%
17, 0.0239, 1.2956, 94.513%, 66.497%
18, 0.0238, 1.2154, 96.510%, 64.345%
19, 0.0237, 1.1607, 97.613%, 65.477%
20, 0.0235, 1.1166, 98.474%, 67.865%
21, 0.0234, 1.0916, 98.802%, 72.901%
22, 0.0232, 1.0698, 99.196%, 74.555%
23, 0.0231, 1.0495, 99.336%, 68.835%
24, 0.0229, 1.0399, 99.409%, 72.541%
25, 0.0227, 1.0320, 99.385%, 80.152%
26, 0.0225, 1.0258, 99.553%, 74.580%
27, 0.0224, 1.0227, 99.487%, 75.414%
28, 0.0222, 1.0209, 99.430%, 71.521%
29, 0.0220, 1.0187, 99.450%, 77.652%
30, 0.0218, 1.0098, 99.532%, 75.152%
31, 0.0216, 1.0031, 99.561%, 72.367%
32, 0.0213, 0.9979, 99.561%, 76.520%
33, 0.0211, 1.0022, 99.516%, 76.707%
34, 0.0209, 1.0029, 99.414%, 75.426%
35, 0.0207, 1.0034, 99.401%, 79.008%
36, 0.0204, 0.9880, 99.602%, 77.167%
37, 0.0202, 0.9905, 99.557%, 78.361%
38, 0.0199, 0.9879, 99.500%, 80.065%
39, 0.0197, 0.9752, 99.615%, 76.296%
40, 0.0194, 0.9754, 99.561%, 78.324%
41, 0.0192, 0.9774, 99.582%, 77.901%
42, 0.0189, 0.9750, 99.594%, 80.463%
43, 0.0187, 0.9702, 99.639%, 79.493%
44, 0.0184, 0.9637, 99.684%, 82.515%
45, 0.0181, 0.9557, 99.668%, 81.072%
46, 0.0178, 0.9569, 99.680%, 79.978%
47, 0.0176, 0.9481, 99.754%, 83.422%
48, 0.0173, 0.9489, 99.738%, 81.569%
49, 0.0170, 0.9529, 99.660%, 79.915%
50, 0.0167, 0.9598, 99.635%, 82.166%
51, 0.0164, 0.9488, 99.721%, 83.920%
52, 0.0161, 0.9463, 99.639%, 79.891%
53, 0.0158, 0.9606, 99.615%, 81.930%
54, 0.0155, 0.9430, 99.705%, 82.651%
55, 0.0152, 0.9376, 99.672%, 81.022%
56, 0.0149, 0.9363, 99.701%, 84.803%
57, 0.0146, 0.9250, 99.820%, 86.245%
58, 0.0143, 0.9202, 99.738%, 85.748%
59, 0.0140, 0.9176, 99.799%, 83.037%
60, 0.0137, 0.9171, 99.770%, 86.668%
61, 0.0134, 0.9131, 99.832%, 86.880%
62, 0.0131, 0.9154, 99.779%, 83.808%
63, 0.0128, 0.9185, 99.762%, 84.828%
64, 0.0125, 0.9197, 99.758%, 86.532%
65, 0.0122, 0.9190, 99.754%, 82.751%
66, 0.0119, 0.9203, 99.697%, 86.245%
67, 0.0116, 0.9094, 99.811%, 85.848%
68, 0.0113, 0.9012, 99.836%, 87.676%
69, 0.0110, 0.8965, 99.885%, 88.584%
70, 0.0107, 0.8932, 99.926%, 88.782%
71, 0.0104, 0.8921, 99.922%, 88.434%
72, 0.0101, 0.8935, 99.861%, 88.944%
73, 0.0098, 0.8906, 99.889%, 88.434%
74, 0.0095, 0.8879, 99.918%, 89.143%
75, 0.0092, 0.8868, 99.947%, 89.753%
76, 0.0089, 0.8869, 99.906%, 88.957%
77, 0.0086, 0.8875, 99.881%, 87.327%
78, 0.0083, 0.8855, 99.918%, 89.603%
79, 0.0080, 0.8838, 99.906%, 89.541%
80, 0.0077, 0.8846, 99.943%, 89.653%
81, 0.0074, 0.8862, 99.918%, 88.857%
82, 0.0072, 0.8835, 99.934%, 89.342%
83, 0.0069, 0.8825, 99.938%, 89.280%
84, 0.0066, 0.8815, 99.922%, 88.422%
85, 0.0063, 0.8810, 99.934%, 89.877%
86, 0.0061, 0.8780, 99.967%, 89.442%
87, 0.0058, 0.8767, 99.984%, 89.392%
88, 0.0056, 0.8764, 99.959%, 90.461%
89, 0.0053, 0.8752, 99.984%, 90.524%
90, 0.0051, 0.8752, 99.984%, 89.889%
91, 0.0048, 0.8738, 99.984%, 90.673%
92, 0.0046, 0.8733, 99.992%, 90.374%
93, 0.0043, 0.8739, 99.971%, 90.710%
94, 0.0041, 0.8732, 99.967%, 90.971%
95, 0.0039, 0.8719, 99.988%, 90.872%
96, 0.0037, 0.8716, 99.975%, 90.648%
97, 0.0034, 0.8709, 99.988%, 90.797%
98, 0.0032, 0.8706, 99.996%, 90.611%
99, 0.0030, 0.8703, 99.996%, 90.810%
100, 0.0028, 0.8700, 99.992%, 90.810%
101, 0.0026, 0.8693, 99.996%, 90.785%
102, 0.0025, 0.8691, 100.000%, 90.996%
103, 0.0023, 0.8688, 100.000%, 90.946%
104, 0.0021, 0.8685, 99.996%, 90.872%
105, 0.0019, 0.8684, 99.996%, 90.760%
106, 0.0018, 0.8679, 100.000%, 90.785%
107, 0.0016, 0.8680, 100.000%, 91.083%
108, 0.0015, 0.8680, 100.000%, 91.096%
109, 0.0013, 0.8673, 100.000%, 91.096%
110, 0.0012, 0.8673, 100.000%, 90.959%
111, 0.0011, 0.8671, 100.000%, 90.834%
112, 0.0010, 0.8668, 100.000%, 90.971%
113, 0.0008, 0.8666, 100.000%, 91.083%
114, 0.0007, 0.8665, 100.000%, 91.021%
115, 0.0006, 0.8666, 100.000%, 91.071%
116, 0.0005, 0.8663, 100.000%, 91.096%
117, 0.0005, 0.8663, 99.996%, 91.145%
118, 0.0004, 0.8662, 100.000%, 91.145%
119, 0.0003, 0.8661, 99.996%, 91.245%
120, 0.0002, 0.8661, 100.000%, 91.195%
121, 0.0002, 0.8659, 99.996%, 91.195%
122, 0.0001, 0.8659, 99.996%, 91.170%
123, 0.0001, 0.8659, 100.000%, 91.121%
124, 0.0001, 0.8659, 100.000%, 91.145%
125, 0.0000, 0.8658, 100.000%, 91.071%
126, 0.0000, 0.8658, 100.000%, 91.096%
127, 0.0000, 0.8658, 100.000%, 91.257%
===== TESTING =====
Dataset 3pts512	ACC:100.00
Dataset val	ACC:91.26
